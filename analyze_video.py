#!/usr/bin/env python3
"""
Script d'analyse de vid√©os utilisant YOLOv8 pr√©-entra√Æn√© sur diff√©rents datasets
Supporte COCO, Open Images V7, et mod√®les personnalis√©s
"""

import cv2 # pour la lecture des vid√©os
import torch # pour le deep learning
from ultralytics import YOLO # pour le mod√®le YOLOv8
import matplotlib.pyplot as plt # pour la visualisation
import matplotlib.patches as patches # pour les bo√Ætes de d√©tection
from PIL import Image # pour la manipulation d'images
import numpy as np # pour les calculs num√©riques
import os # pour le syst√®me de fichiers
import time # pour mesurer les performances

_model_cache = {}

# Informations sur les datasets support√©s
DATASET_INFO = {
    'coco': {
        'name': 'COCO',
        'full_name': 'Common Objects in Context',
        'classes': None, # 80 classes
        'num_classes': 80,
        'website': 'https://cocodataset.org/',
        'description': 'Dataset g√©n√©raliste avec 80 classes d\'objets communs'
    },
    'oiv7': {
        'name': 'Open Images V7',
        'full_name': 'Open Images Dataset V7',
        'classes': None,  # 600 classes
        'num_classes': 600,
        'website': 'https://storage.googleapis.com/openimages/web/index.html',
        'description': 'Dataset large avec 600 classes d\'objets vari√©s'
    },
    'seg': {
        'name': 'Segmentation',
        'full_name': 'YOLOv8 Segmentation (COCO)',
        'classes': None,  # 80 classes COCO
        'num_classes': 80,
        'website': 'https://cocodataset.org/',
        'description': 'Segmentation d\'objets avec masques de pixels pr√©cis'
    },
    'custom-trained': {
        'name': 'Mod√®le personnalis√©',
        'full_name': 'Mod√®le personnalis√©',
        'classes': None,  # 4 classes
        'num_classes': 4,
        'website': 'https://github.com/ultralytics/ultralytics',
        'description': 'Mod√®le YOLOv8 fine-tun√© sur dataset Aerial Cars'
    }
}

def detect_dataset_type(model_path):
    """
    D√©tecte le type de dataset bas√© sur le nom du mod√®le
    
    Args:
        model_path (str): Chemin vers le mod√®le
        
    Returns:
        str: Type de dataset ('coco', 'oiv7', 'seg', 'custom-trained')
    """
    if 'best.pt' in model_path:
        return 'custom-trained'
    elif '11' in model_path:
        if model_path[6] == 'n':
            return 'nv11-coco'
        elif model_path[6] == 's':
            return 'sv11-coco'
        elif model_path[6] == 'm':
            return 'mv11-coco'
        elif model_path[6] == 'l':
            return 'lv11-coco'
        elif model_path[6] == 'x':
            return 'xv11-coco'
    elif 'seg' in model_path:
        if model_path[6] == 'n':
            return 'n-seg'
        elif model_path[6] == 's':
            return 's-seg'
        elif model_path[6] == 'm':
            return 'm-seg'
        elif model_path[6] == 'l':
            return 'l-seg'
        elif model_path[6] == 'x':
            return 'x-seg'
    elif 'oiv7' in model_path:
        if model_path[6] == 'n':
            return 'n-oiv7'
        elif model_path[6] == 's':
            return 's-oiv7'
        elif model_path[6] == 'm':
            return 'm-oiv7'
        elif model_path[6] == 'l':
            return 'l-oiv7'
        elif model_path[6] == 'x':
            return 'x-oiv7'
    else:
        if model_path[6] == 'n':
            return 'n-coco'
        elif model_path[6] == 's':
            return 's-coco'
        elif model_path[6] == 'm':
            return 'm-coco'
        elif model_path[6] == 'l':
            return 'l-coco'
        elif model_path[6] == 'x':
            return 'x-coco'


def get_model(model_path):
    """
    R√©cup√®re un mod√®le depuis le cache ou le charge s'il n'existe pas
    
    Args:
        model_path (str): Chemin vers le mod√®le YOLOv8
        
    Returns:
        YOLO: Mod√®le YOLOv8 charg√©
    """
    if model_path not in _model_cache:
        print(f"üîÑ Chargement du mod√®le {model_path}...")
        try:
            _model_cache[model_path] = YOLO(model_path)
            print(f"‚úÖ Mod√®le {model_path} charg√© avec succ√®s")
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
            raise
    else:
        print(f"‚ôªÔ∏è  Utilisation du mod√®le {model_path} depuis le cache")
    
    return _model_cache[model_path]

def analyze_video(video_path, model_path, seuil_conf):
    """
    Analyse une vid√©o avec YOLOv8 pr√©-entra√Æn√© sur diff√©rents datasets
    
    Args:
        video_path (str): Chemin vers la vid√©o √† analyser
        model_path (str): Chemin vers le mod√®le YOLOv8
        seuil_conf (float): Seuil de confiance minimum
    """
    
    # D√©tecter le type de dataset
    dataset_type = detect_dataset_type(model_path)
    if dataset_type == 'custom-trained':
        dataset_info = DATASET_INFO[dataset_type]
    else:
        dataset_info = DATASET_INFO[dataset_type.split('-')[1]]
    
    # V√©rifier si la vid√©o existe
    try:
        cap = cv2.VideoCapture(video_path)
        if cap is None:
            print(f"‚ùå Erreur: Impossible de charger la vid√©o {video_path}")
            return
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement de la vid√©o: {e}")
        cap.release()
        return
    
    # R√©cup√©rer le mod√®le (depuis le cache ou le charger)
    try:
        model = get_model(model_path)
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
        cap.release()
        return
    
    print(f"\nüé¨ ANALYSE VID√âO YOLOV8 + DATASET {dataset_info['name'].upper()}")
    print("=" * 50)

    # Obtenir les propri√©t√©s de la vid√©o
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    
    print(f"üé• Propri√©t√©s de la vid√©o:")
    print(f"   üìè R√©solution: {width}x{height}")
    print(f"   ‚è±Ô∏è  FPS: {fps}")
    print(f"   üìä Frames totales: {total_frames}")
    print(f"   ‚è∞ Dur√©e: {duration:.1f} secondes")
    print(f"   üéØ Seuil de confiance: {seuil_conf}")
    print()
    
    # Statistiques
    frame_count = 0
    total_detections = 0
    detection_history = []
    start_time = time.time()
    
    # Couleurs pour les bo√Ætes de d√©tection et masques
    colors = plt.cm.tab10(np.linspace(0, 1, 10))
    
    print("üöÄ D√©but de l'analyse...")
    
    try:
        # Cr√©er une fen√™tre pour afficher la vid√©o
        cv2.namedWindow("Analyse Video YOLOv8", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Analyse Video YOLOv8", 2560, 1440)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # Afficher le progr√®s
            if frame_count % 30 == 0:  # Toutes les 30 frames
                progress = (frame_count / total_frames) * 100
                print(f"üìä Progr√®s: {progress:.1f}% ({frame_count}/{total_frames} frames)")
            
            # Effectuer la d√©tection sur la frame
            try:
                results = model(frame, conf=seuil_conf)
                result = results[0]
                
                # Compter les d√©tections
                frame_detections = 0
                if result.boxes is not None and result.masks is None:
                    frame_detections = len(result.boxes)
                    total_detections += frame_detections
                
                detection_history.append(frame_detections)
                
                # Dessiner les d√©tections sur la frame
                annotated_frame = frame.copy()
                
                # Dessiner les masques s'ils existent
                if result.masks is not None:
                    for i, mask in enumerate(result.masks):
                        try:
                            mask_array = mask.data[0].cpu().numpy()
                            
                            # V√©rifications de s√©curit√©
                            if mask_array.size == 0 or mask_array.shape[0] == 0 or mask_array.shape[1] == 0:
                                continue
                            
                            # Redimensionner le masque seulement si n√©cessaire
                            if mask_array.shape != (height, width):
                                if mask_array.shape[0] > 0 and mask_array.shape[1] > 0:
                                    mask_resized = cv2.resize(mask_array.astype(np.uint8), 
                                                            (width, height))
                                else:
                                    continue
                            else:
                                mask_resized = mask_array.astype(np.uint8)
                            
                            # Cr√©er un masque color√©
                            color = colors[i % len(colors)]
                            colored_mask = np.zeros((height, width, 3), dtype=np.uint8)
                            colored_mask[mask_resized == 1] = [int(c * 255) for c in color[:3]]
                            
                            # Dessiner uniquement les contours du masque
                            contours, _ = cv2.findContours(mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                            cv2.drawContours(annotated_frame, contours, -1, [int(c * 255) for c in color[:3]], 2)

                            # Calculer le centre du contour pour placer le label
                            for contour in contours:
                                M = cv2.moments(contour)
                                if M["m00"] != 0:
                                    cx = int(M["m10"] / M["m00"])
                                    cy = int(M["m01"] / M["m00"])
                                    
                                    # CORRECTION : Utiliser result.boxes pour obtenir la classe et la confiance
                                    if result.boxes is not None and i < len(result.boxes):
                                        box = result.boxes[i]
                                        class_id = int(box.cls[0].cpu().numpy())
                                        class_name = result.names[class_id]
                                        confidence = box.conf[0].cpu().numpy()
                                        
                                        # Ajouter le label avec fond color√©
                                        label = f"{class_name} {confidence:.2f}"
                                        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                                        
                                        # Dessiner le fond du label
                                        cv2.rectangle(annotated_frame, 
                                                    (cx - label_w//2, cy - label_h - 10),
                                                    (cx + label_w//2, cy), 
                                                    [int(c * 255) for c in color[:3]], 
                                                    -1)
                                        
                                        # Dessiner le texte
                                        cv2.putText(annotated_frame, 
                                                  label, 
                                                  (cx - label_w//2, cy - 5),
                                                  cv2.FONT_HERSHEY_SIMPLEX, 
                                                  0.6, 
                                                  (255, 255, 255), 
                                                  2)
                            
                        except Exception as e:
                            print(f"‚ö†Ô∏è  Erreur masque {i}: {e}")
                            continue
                
                # Dessiner les bo√Ætes de d√©tection
                if result.boxes is not None and result.masks is None:
                    for i, box in enumerate(result.boxes):
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                        confidence = box.conf[0].cpu().numpy()
                        class_id = int(box.cls[0].cpu().numpy())
                        class_name = result.names[class_id]
                        
                        # Dessiner la bo√Æte
                        color = colors[i % len(colors)]
                        color_bgr = [int(c * 255) for c in color[:3]]
                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color_bgr, 2)
                        
                        # Ajouter le label avec fond color√©
                        label = f"{class_name} {confidence:.2f}"
                        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                        cv2.rectangle(annotated_frame, (x1, y1-label_h-10), (x1+label_w, y1), color_bgr, -1)
                        cv2.putText(annotated_frame, label, (x1, y1 - 5), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # Ajouter des informations sur la frame avec fond color√©
                info_text = f"Frame: {frame_count}/{total_frames} | Detections: {frame_detections}"
                (text_w, text_h), _ = cv2.getTextSize(info_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
                cv2.rectangle(annotated_frame, (5, 5), (15+text_w, 35+text_h), (0, 100, 0), -1)
                cv2.putText(annotated_frame, info_text, (10, 30), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                # Redimensionner pour un affichage plus grand
                max_width = 2560
                max_height = 1440
                if width > max_width or height > max_height:
                    scale = min(max_width/width, max_height/height)
                    new_width = int(width * scale)
                    new_height = int(height * scale)
                    annotated_frame = cv2.resize(annotated_frame, (new_width, new_height))
                else:
                    # Agrandir la vid√©o si elle est plus petite que la taille maximale
                    scale = min(max_width/width, max_height/height)
                    if scale > 1:
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        annotated_frame = cv2.resize(annotated_frame, (new_width, new_height))
                
                # Afficher la frame
                cv2.imshow('Analyse Video YOLOv8', annotated_frame)
                
                # Attendre 1ms et v√©rifier si l'utilisateur veut quitter (touche 'q')
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\n‚èπÔ∏è  Analyse interrompue par l'utilisateur")
                    break
                
            except Exception as e:
                print(f"‚ùå Erreur lors de l'analyse de la frame {frame_count}: {e}")
                continue
    
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Analyse interrompue par l'utilisateur")
    
    finally:
        # Nettoyer
        cap.release()       
        
        # Calculer les statistiques finales
        end_time = time.time()
        processing_time = end_time - start_time
        avg_fps = frame_count / processing_time if processing_time > 0 else 0
        
        print(f"\nüìä R√âSULTATS DE L'ANALYSE")
        print("=" * 50)
        print(f"üé¨ Frames trait√©es: {frame_count}")
        print(f"üîç Total d√©tections: {total_detections}")
        print(f"üìà Moyenne d√©tections/frame: {total_detections/frame_count:.2f}")
        print(f"‚è±Ô∏è  Temps de traitement: {processing_time:.1f} secondes")
        print(f"‚ö° FPS de traitement: {avg_fps:.1f}")
        print(f"üéØ FPS vid√©o original: {fps}")
        
        print(f"\nüèÅ Analyse termin√©e!")
        print()

def show_dataset_info(dataset_type):
    """
    Affiche les informations sur le dataset utilis√©
    
    Args:
        dataset_type (str): Type de dataset ('coco', 'oiv7', 'seg')
    """

    # Gestion du mod√®le personnalis√©
    if dataset_type == 'custom-trained':
        print()
        print(f"üìä INFORMATIONS MOD√àLE PERSONNALIS√â")
        print("=" * 50)
        print(f"üìö Dataset: Mod√®le entra√Æn√© personnalis√©")
        print(f"üî¢ Nombre de classes: 4")
        print(f"üåê Type: D√©tection de v√©hicules a√©riens")
        print(f"üìù Description: Mod√®le YOLOv8 fine-tun√© sur dataset Aerial Cars")
        print()
        print("üè∑Ô∏è Classes d√©tect√©es:")
        print("   üöó car")
        print("   üöõ truck") 
        print("   üöå bus")
        print("   üöê van")
        print()
        return

    # Gestion des datasets pr√©-entra√Æn√©s
    dataset_info = DATASET_INFO[dataset_type.split('-')[1]]
    
    print()
    print(f"üìä INFORMATIONS DATASET {dataset_info['name'].upper()}")
    print("=" * 50)
    print(f"üìö Dataset: {dataset_info['full_name']}")
    print(f"üî¢ Nombre de classes: {dataset_info['num_classes']}")
    print(f"üåê Site officiel: {dataset_info['website']}")
    print(f"üìù Description: {dataset_info['description']}")
    print()
    
    if dataset_type == 'coco':
        print("üè∑Ô∏è Cat√©gories principales:")
        print("   üë• Personnes: person")
        print("   üöó V√©hicules: car, bus, truck, motorcycle, bicycle, etc.")
        print("   üêï Animaux: cat, dog, horse, cow, sheep, bird, etc.")
        print("   üè† Objets: chair, table, laptop, cell phone, book, etc.")
        print("   üçé Nourriture: apple, banana, pizza, cake, etc.")
        print("   ‚öΩ Sports: sports ball, tennis racket, baseball bat, etc.")
    elif dataset_type == 'oiv7':
        print("üè∑Ô∏è Cat√©gories principales:")
        print("   üë• Personnes et parties du corps")
        print("   üöó V√©hicules de tous types")
        print("   üêï Animaux domestiques et sauvages")
        print("   üè† Objets du quotidien")
        print("   üçé Nourriture et boissons")
        print("   ‚öΩ Sports et loisirs")
        print("   üé® Art et culture")
        print("   üåç Nature et environnement")
    elif dataset_type == 'seg':
        print("üé® Fonctionnalit√©s de segmentation:")
        print("   üîç D√©tection d'objets + masques de pixels")
        print("   üìê Contours pr√©cis des objets")
        print("   üéØ 80 classes COCO avec segmentation")
        print("   üí° Id√©al pour l'√©dition de vid√©os et la robotique")
    print()

def main():
    """Fonction principale"""    
    # Exemples de mod√®les pour diff√©rents datasets :
    model_paths = {
        # Mod√®les de D√âTECTION
        'n-coco': "yolov8n.pt",           
        's-coco': "yolov8s.pt",           
        'm-coco': "yolov8m.pt",           
        'l-coco': "yolov8l.pt",           
        'x-coco': "yolov8x.pt",           
        
        # Mod√®les de SEGMENTATION
        'n-seg': "yolov8n-seg.pt",
        's-seg': "yolov8s-seg.pt", 
        'm-seg': "yolov8m-seg.pt",
        'l-seg': "yolov8l-seg.pt",
        'x-seg': "yolov8x-seg.pt",
        
        # Mod√®les Open Images V7
        'n-oiv7': "yolov8n-oiv7.pt",      
        's-oiv7': "yolov8s-oiv7.pt",      
        'm-oiv7': "yolov8m-oiv7.pt",      
        'l-oiv7': "yolov8l-oiv7.pt",      
        'x-oiv7': "yolov8x-oiv7.pt",      

        # Mod√®les personnalis√©s
        'custom-trained': "runs/train6/weights/best.pt",

        # Mod√®les YOLOv11
        'nv11-coco': "yolo11n.pt",
        'sv11-coco': "yolo11s.pt",
        'mv11-coco': "yolo11m.pt",
        'lv11-coco': "yolo11l.pt",
        'xv11-coco': "yolo11x.pt",
    }
    
    # Choisir le dataset √† utiliser
    dataset_choice = 'n-seg' 
    model_path = model_paths[dataset_choice]

    # Configuration - Changez ces valeurs pour tester diff√©rents datasets
    video_path = "Videos/test.mp4"

    # Choisir le seuil de confiance
    seuil_conf = 0.5
    
    # Afficher les informations sur le dataset
    show_dataset_info(dataset_choice)
    
    # Lancer l'analyse
    analyze_video(video_path, model_path, seuil_conf)

if __name__ == "__main__":
    main()
