# Analyseur d'images et vidÃ©os YOLOv8 + PyTorch + Multi-Datasets + EntraÃ®nement PersonnalisÃ©

Ce projet analyse des images et vidÃ©os en utilisant YOLOv8 prÃ©-entraÃ®nÃ© sur diffÃ©rents datasets avec PyTorch pour dÃ©tecter, classifier et segmenter les objets selon les classes disponibles dans chaque dataset. Il inclut Ã©galement la possibilitÃ© d'entraÃ®ner des modÃ¨les personnalisÃ©s avec Docker.

## ğŸš€ Installation

### MÃ©thode 1 : Installation automatique (RecommandÃ©e)

```bash
# 1. Aller dans le dossier du projet
cd YOLO_Object_Detection

# 2. ExÃ©cuter le script d'installation
chmod +x install.sh
./install.sh
```

Le script d'installation :
- âœ… VÃ©rifie que Python 3 et pip sont installÃ©s
- ğŸ“¦ CrÃ©e un environnement virtuel (recommandÃ©)
- ğŸ“¥ Installe automatiquement toutes les dÃ©pendances
- ğŸ”§ Rend les scripts exÃ©cutables

### MÃ©thode 2 : Installation manuelle

#### Ã‰tape 1 : CrÃ©er un environnement virtuel

```bash
# CrÃ©er l'environnement virtuel
python3 -m venv venv

# Activer l'environnement virtuel
source venv/bin/activate  
```

#### Ã‰tape 2 : Installer les dÃ©pendances

```bash
# Avec l'environnement virtuel activÃ©
pip install -r requirements.txt
```

**DÃ©pendances installÃ©es :**
- `ultralytics>=8.0.0` - Framework YOLOv8 (8.3.209 pour YOLOv11)
- `torch>=1.9.0` - PyTorch pour le deep learning
- `torchvision>=0.10.0` - Vision utilities
- `opencv-python>=4.5.0` - Traitement d'images
- `Pillow>=8.0.0` - Manipulation d'images
- `matplotlib>=3.3.0` - Visualisation
- `numpy>=1.21.0` - Calculs numÃ©riques

## ğŸ¤” Pourquoi un environnement virtuel ?

### Le problÃ¨me sur macOS avec Homebrew

SystÃ¨me gÃ©rÃ© par **Homebrew**, qui empÃªche l'installation directe de packages pour protÃ©ger votre installation systÃ¨me :

```
error: externally-managed-environment
```

### Avantages de l'environnement virtuel

1. **ğŸ”’ SÃ©curitÃ©** : N'affecte pas votre Python systÃ¨me
2. **ğŸ¯ Isolation** : Chaque projet a ses propres versions de packages
3. **ğŸ”„ ReproductibilitÃ©** : MÃªme environnement sur diffÃ©rentes machines
4. **ğŸ§¹ PropretÃ©** : Facile Ã  supprimer si besoin
5. **âš¡ Performance** : Ã‰vite les conflits de versions

### Activation de l'environnement virtuel

**Important :** Vous devez activer l'environnement virtuel Ã  chaque nouvelle session terminal :

```bash
cd YOLO_Object_Detection
source venv/bin/activate
```

**Comment savoir si l'environnement est activÃ© :**
- Le prompt affiche `(venv)` au dÃ©but
- `which python` pointe vers le dossier `venv/bin/python`


## ğŸ“¸ Analyse d'images

### Analyser une image avec diffÃ©rents datasets

```bash
# Lancer l'analyse d'image
python analyze_image.py
```

### Ce que fait le script d'analyse d'images

1. **ğŸ“Š Affiche les informations** sur le dataset sÃ©lectionnÃ©
2. **ğŸ“¥ Charge l'image** spÃ©cifiÃ©e
3. **ğŸ¤– Charge le modÃ¨le** YOLOv8 prÃ©-entraÃ®nÃ© (avec cache pour Ã©viter les rechargements)
4. **ğŸ” Analyse l'image** avec PyTorch et YOLOv8 selon les classes du dataset
5. **ğŸ“Š Affiche les rÃ©sultats** : objets dÃ©tectÃ©s + ID + confiance + position
6. **ğŸ–¼ï¸ CrÃ©e une visualisation** avec des boÃ®tes de dÃ©tection et contours de segmentation

## ğŸ¬ Analyse de vidÃ©os

### Analyser une vidÃ©o en temps rÃ©el

```bash
# Lancer l'analyse de vidÃ©o
python analyze_video.py
```

### Ce que fait le script d'analyse de vidÃ©os

1. **ğŸ“Š Affiche les informations** sur le dataset sÃ©lectionnÃ©
2. **ğŸ“¥ Charge la vidÃ©o** spÃ©cifiÃ©e
3. **ğŸ¤– Charge le modÃ¨le** YOLOv8 prÃ©-entraÃ®nÃ© (avec cache pour Ã©viter les rechargements)
4. **ğŸ” Analyse chaque frame** avec PyTorch et YOLOv8 selon les classes du dataset
5. **ğŸ“Š Affiche les statistiques** : frames traitÃ©es, dÃ©tections totales, FPS de traitement
6. **ğŸ–¼ï¸ Affiche la vidÃ©o en temps rÃ©el** avec des boÃ®tes de dÃ©tection et contours de segmentation
7. **âŒ¨ï¸ ContrÃ´les** : Appuyez sur 'q' pour quitter l'analyse

### FonctionnalitÃ©s spÃ©ciales pour les vidÃ©os

- **ğŸ¥ Affichage en temps rÃ©el** : Visualisation frame par frame avec annotations
- **ğŸ“Š Statistiques en direct** : Compteur de frames, dÃ©tections par frame
- **ğŸ–¥ï¸ Redimensionnement automatique** : Adaptation Ã  la taille d'Ã©cran (max 2560x1440)

## âš™ï¸ Configuration des datasets

### Utilisation des modÃ¨les prÃ©-entraÃ®nÃ©s

Dans `analyze_image.py` et `analyze_video.py`, vous pouvez choisir le dataset Ã  utiliser :

```python
# Exemples de modÃ¨les pour diffÃ©rents datasets :
model_paths = {
    # DÃ‰TECTION COCO (80 classes)
    'n-coco': "yolov8n.pt",           
    's-coco': "yolov8s.pt",           
    'm-coco': "yolov8m.pt",           
    'l-coco': "yolov8l.pt",           
    'x-coco': "yolov8x.pt",           
    
    # SEGMENTATION COCO (80 classes + masques)
    'n-seg': "yolov8n-seg.pt",
    's-seg': "yolov8s-seg.pt", 
    'm-seg': "yolov8m-seg.pt",
    'l-seg': "yolov8l-seg.pt",
    'x-seg': "yolov8x-seg.pt",
    
    # DÃ‰TECTION Open Images V7 (600 classes)
    'n-oiv7': "yolov8n-oiv7.pt",      
    's-oiv7': "yolov8s-oiv7.pt",      
    'm-oiv7': "yolov8m-oiv7.pt",      
    'l-oiv7': "yolov8l-oiv7.pt",      
    'x-oiv7': "yolov8x-oiv7.pt",  

    # ModÃ¨les personnalisÃ©s
    'custom-trained': "runs/train/weights/best.pt",   

    # ModÃ¨les YOLOv11
    'nv11-coco': "yolo11n.pt",
    'sv11-coco': "yolo11s.pt",
    'mv11-coco': "yolo11m.pt",
    'lv11-coco': "yolo11l.pt",
    'xv11-coco': "yolo11x.pt",
}

# Choisir le dataset Ã  utiliser
dataset_choice = 'm-seg'  # Segmentation COCO Medium
```

### ğŸ¯ Dataset COCO (Common Objects in Context)

**Le plus populaire et performant pour la dÃ©tection d'objets gÃ©nÃ©raux**

#### CaractÃ©ristiques
- **ğŸ”¢ 80 classes d'objets** 
- **ğŸ“ˆ 118,287 images d'entraÃ®nement**
- **ğŸ“ˆ 5,000 images de validation**
- **ğŸ“ˆ 40,670 images de test**
- **ğŸ¯ 1.5 million d'objets annotÃ©s**
- **ğŸŒ Site officiel** : https://cocodataset.org/

#### ModÃ¨les disponibles
- **DÃ©tection** : `yolov8n.pt` Ã  `yolov8x.pt` (boÃ®tes de dÃ©tection)
- **Segmentation** : `yolov8n-seg.pt` Ã  `yolov8x-seg.pt` (masques de pixels)

### ğŸŒ Dataset Open Images V7

**Dataset trÃ¨s large avec de nombreuses classes spÃ©cialisÃ©es**

#### CaractÃ©ristiques
- **ğŸ”¢ 600 classes d'objets** trÃ¨s variÃ©es
- **ğŸ“ˆ Plus de 9 millions d'images**
- **ğŸ¯ Plus de 36 millions de boÃ®tes de dÃ©tection**
- **ğŸŒ Site officiel** : https://storage.googleapis.com/openimages/web/index.html

#### ModÃ¨les disponibles
- **DÃ©tection uniquement** : `yolov8n-oiv7.pt` Ã  `yolov8x-oiv7.pt`
- **âŒ Pas de segmentation** : Open Images V7 ne propose pas de modÃ¨les de segmentation

#### Avantages
- **ğŸ¯ Classes trÃ¨s spÃ©cifiques** : DiffÃ©rents types de chiens, voitures, etc.
- **ğŸŒ DiversitÃ©** : Couvre de nombreux domaines spÃ©cialisÃ©s
- **ğŸ“Š Ã‰chelle** : Dataset trÃ¨s large

#### InconvÃ©nients
- **âš ï¸ PrÃ©cision moindre** : Moins performant que COCO sur les objets gÃ©nÃ©raux
- **ğŸ“Š Classes dÃ©sÃ©quilibrÃ©es** : Certaines classes trÃ¨s rares
- **ğŸ” ComplexitÃ©** : Plus difficile Ã  utiliser efficacement

### ğŸ”„ SystÃ¨me de cache intelligent

Le script utilise un **systÃ¨me de cache global** pour Ã©viter de recharger les modÃ¨les :

```python
# Cache global pour les modÃ¨les chargÃ©s
_model_cache = {}

def get_model(model_path):
    """
    RÃ©cupÃ¨re un modÃ¨le depuis le cache ou le charge s'il n'existe pas
    """
    if model_path not in _model_cache:
        print(f"ğŸ”„ Chargement du modÃ¨le {model_path}...")
        _model_cache[model_path] = YOLO(model_path)
        print(f"âœ… ModÃ¨le {model_path} chargÃ© avec succÃ¨s")
    else:
        print(f"â™»ï¸  Utilisation du modÃ¨le {model_path} depuis le cache")
    
    return _model_cache[model_path]
```

## ğŸ§  Comment fonctionne YOLO ?

### Qu'est-ce que YOLO ?

**YOLO** (You Only Look Once) est un rÃ©seau de neurones convolutifs spÃ©cialisÃ© dans la **dÃ©tection d'objets en temps rÃ©el**.

### Principe de fonctionnement

1. **ğŸ” Analyse globale** : YOLO examine l'image entiÃ¨re en une seule fois
2. **ğŸ“¦ DÃ©tection simultanÃ©e** : Trouve tous les objets en parallÃ¨le
3. **ğŸ¯ PrÃ©diction directe** : PrÃ©dit directement les boÃ®tes de dÃ©tection
4. **âš¡ Vitesse** : Beaucoup plus rapide que les mÃ©thodes traditionnelles

### Processus de detection et segmentation

1. **ğŸ“¥ EntrÃ©e** : Image redimensionnÃ©e Ã  640x640 pixels
2. **ğŸ§  Traitement** : Le rÃ©seau extrait des caractÃ©ristiques
3. **ğŸ¯ PrÃ©diction** : Pour chaque zone, prÃ©dit :
   - **Position** : CoordonnÃ©es de la boÃ®te (x1, y1, x2, y2)
   - **Confiance** : ProbabilitÃ© que ce soit un objet (0-1)
   - **Classe** : Type d'objet selon le dataset utilisÃ©
   - **Masque** : Masque de pixels prÃ©cis de l'objet
4. **ğŸ” Filtrage** : Garde seulement les dÃ©tections avec confiance > seuil
5. **ğŸ“Š RÃ©sultat** : Liste des objets segmentÃ©s avec boÃ®tes + masques

### ModÃ¨les YOLOv8 disponibles

| Taille | DÃ©tection COCO | Segmentation COCO | DÃ©tection OIV7 | Vitesse | PrÃ©cision | Usage |
|--------|----------------|-------------------|----------------|---------|-----------|-------|
| Nano   | yolov8n.pt | yolov8n-seg.pt | yolov8n-oiv7.pt | +++ | ++ | Mobile, IoT |
| Small  | yolov8s.pt | yolov8s-seg.pt | yolov8s-oiv7.pt | ++ | +++ | Ã‰quilibre |
| **Medium** | **yolov8m.pt** | **yolov8m-seg.pt** | **yolov8m-oiv7.pt** | + | ++++ | **RecommandÃ©** |
| Large  | yolov8l.pt | yolov8l-seg.pt | yolov8l-oiv7.pt | - | +++++ | Haute prÃ©cision |
| Huge   | yolov8x.pt | yolov8x-seg.pt | yolov8x-oiv7.pt | -- | +++++ | Recherche |

### YOLOv8 vs YOLOv11

| CaractÃ©ristique | YOLOv8 | YOLOv11 |
|----------------|---------|----------|
| **AnnÃ©e** | 2023 | 2024 |
| **mAP COCO** | 53.9% (m) | 54.7% (m) |
| **Vitesse** | RÃ©fÃ©rence | LÃ©gÃ¨rement plus lent |
| **PrÃ©cision** | Excellente | AmÃ©liorÃ©e (+0.8%) |
| **Architecture** | C2f backbone | C3k2 + C2PSA |
| **ParamÃ¨tres** | Plus lÃ©ger | LÃ©gÃ¨rement plus lourd |
| **Usage recommandÃ©** | Production | Haute prÃ©cision |


## ğŸ“ EntraÃ®nement de ModÃ¨les PersonnalisÃ©s

### PrÃ©requis
- Docker Desktop installÃ©
- Dataset au format YOLO (images + labels)

### Structure pour l'EntraÃ®nement
```
YOLO_Object_Detection/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ my_dataset/
â”‚       â””â”€â”€ Nom_du_dataset.yolov8/
â”‚           â”œâ”€â”€ train/
â”‚           â”‚   â”œâ”€â”€ images/
â”‚           â”‚   â””â”€â”€ labels/
â”‚           â”œâ”€â”€ valid/
â”‚           â”‚   â”œâ”€â”€ images/
â”‚           â”‚   â””â”€â”€ labels/
â”‚           â””â”€â”€ data.yaml
â”œâ”€â”€ runs/
â”‚   â””â”€â”€ train/
â”‚       â”œâ”€â”€ weights/
â”‚       â”‚   â”œâ”€â”€ best.pt      # Meilleur modÃ¨le
â”‚       â”‚   â””â”€â”€ last.pt      # Dernier modÃ¨le
â”‚       â””â”€â”€ results.png      # Courbes d'entraÃ®nement
â”œâ”€â”€ Dockerfile               # Image Docker pour entraÃ®nement
â”œâ”€â”€ DOCKER_GUIDE.md          # Guide complet d'entraÃ®nement
â””â”€â”€ ...
```

### EntraÃ®nement avec Docker

#### Sur Mac (ARM64)

1. **CrÃ©er l'image Docker :**
```bash
docker build -f Dockerfile.arm64 -t my-yolo-arm64 .
```

2. **Lancer l'entraÃ®nement :**
```bash
docker run --rm -it \
  -v "$PWD":/workspace \
  my-yolo-arm64 \
  yolo train model=yolov8n.pt \
       data="/workspace/datasets/my_dataset/data.yaml" \
       epochs=50 imgsz=640 batch=8 workers=0 project=/workspace/runs
```

#### Sur PC Linux/Windows (AMD64)

1. **CrÃ©er l'image Docker :**
```bash
docker build -f Dockerfile.amd64 -t my-yolo-amd64 .
```

2. **Lancer l'entraÃ®nement :**
```bash
docker run --rm -it \
  -v "$PWD":/workspace \
  my-yolo-amd64 \
  yolo train model=yolov8x.pt \
       data="/workspace/datasets/my_dataset/data.yaml" \
       epochs=100 imgsz=640 batch=16 workers=4 project=/workspace/runs
```

#### Sur PC avec GPU (AMD64)

1. **CrÃ©er l'image Docker :**
```bash
docker build -f Dockerfile.gpu -t my-yolo-gpu . 
```

2. **Lancer l'entraÃ®nement :**
```bash
docker run --rm -it --gpus all \
  -v "$PWD":/workspace \
  my-yolo-gpu \
  yolo train model=yolov8x-seg.pt \
       data="/workspace/datasets/my_dataset/data.yaml" \
       epochs=500 imgsz=640 batch=32 device=0 project=/workspace/runs
```

3. **Utiliser le modÃ¨le entraÃ®nÃ© :**
```python
# Dans analyze_image.py ou analyze_video.py
model_path = "custom-trained"
```

### Guide Complet
Consultez `DOCKER_GUIDE.md` pour un guide dÃ©taillÃ© sur l'entraÃ®nement de modÃ¨les personnalisÃ©s.

## ğŸ“ Structure du projet

```
YOLO_Object_Detection/
â”œâ”€â”€ venv/                    # Environnement virtuel Python
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ install.sh               # Script d'installation automatique
â”œâ”€â”€ analyze_image.py         # Script d'analyse d'images multi-datasets
â”œâ”€â”€ analyze_video.py         # Script d'analyse de vidÃ©os multi-datasets
â”œâ”€â”€ Dockerfile.arm64         # Image Docker pour Mac Apple Silicon
â”œâ”€â”€ Dockerfile.amd64         # Image Docker pour PC (CPU)
â”œâ”€â”€ Dockerfile.gpu           # Image Docker pour PC avec GPU NVIDIA
â”œâ”€â”€ DOCKER_GUIDE.md          # Guide d'entraÃ®nement avec Docker
â”œâ”€â”€ datasets/                # Datasets pour entraÃ®nement
â”œâ”€â”€ runs/                    # RÃ©sultats d'entraÃ®nement
â”œâ”€â”€ Images/                  # Images de test
â”œâ”€â”€ Videos/                  # Video de test
â””â”€â”€ README.md                # Ce fichier

```

**Fichiers gÃ©nÃ©rÃ©s automatiquement :**
- `venv/` - Environnement virtuel crÃ©Ã© lors de l'installation
- `yolov8*.pt` - ModÃ¨les YOLOv8 tÃ©lÃ©chargÃ©s automatiquement (~50-200MB chacun)
- `output.png` - sauvegarde de l'image analysÃ©e 
- `runs/train/weights/` - ModÃ¨les entraÃ®nÃ©s personnalisÃ©s

## ğŸ“– Ressources supplÃ©mentaires

- [Documentation Ultralytics](https://docs.ultralytics.com/)
- [Dataset COCO](https://cocodataset.org/)
- [Dataset Open Images V7](https://storage.googleapis.com/openimages/web/index.html)
- [Roboflow Universe](https://universe.roboflow.com/)
- [YOLOv8 Paper](https://arxiv.org/abs/2305.09972)
- [Docker Documentation](https://docs.docker.com/)

## ğŸ“„ Licence

Ce projet utilise la bibliothÃ¨que Ultralytics (licence AGPL-3.0) et PyTorch.